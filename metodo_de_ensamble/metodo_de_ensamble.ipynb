{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRABAJO PRACTICO FINAL - METODO DE ENSAMBLE - TITANIC\n",
    "# Sistemas de Soporte para la Toma de Decisiones\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from sklearn import tree \n",
    "# from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split # , GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report, \n",
    "                             roc_auc_score, RocCurveDisplay)\n",
    "# import warnings\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier # , RandomForestClassifier \n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "1. CARGANDO DATOS DEL TITANIC\n",
      "================================================================================\n",
      "\n",
      "Dimensiones del conjunto de entrenamiento: (891, 9)\n",
      "\n",
      "Primeras 5 filas:\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  FamilySize  IsAlone\n",
      "0         0       3    1  22.0      1      0   7.2500           2        0\n",
      "1         1       1    0  38.0      1      0  71.2833           2        0\n",
      "2         1       3    0  26.0      0      0   7.9250           1        1\n",
      "3         1       1    0  35.0      1      0  53.1000           2        0\n",
      "4         0       3    1  35.0      0      0   8.0500           1        1\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. CARGA DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"1. CARGANDO DATOS DEL TITANIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Rutas de los archivos\n",
    "ruta_train = r\"..\\data\\dataset_train.csv\"\n",
    "ruta_test = r\"..\\data\\dataset_test.csv\"\n",
    "\n",
    "# Cargar datasets\n",
    "df_train = pd.read_csv(ruta_train)\n",
    "# df_test = pd.read_csv(ruta_test)\n",
    "\n",
    "print(f\"\\nDimensiones del conjunto de entrenamiento: {df_train.shape}\")\n",
    "# print(f\"Dimensiones del conjunto de prueba: {df_test.shape}\")\n",
    "\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "print(df_train.head())\n",
    "\n",
    "# print(\"\\nInformacion general del dataset:\")\n",
    "# print(df_train.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "4. DIVISION DE DATOS\n",
      "================================================================================\n",
      "\n",
      "Train: (712, 8) - Test: (179, 8)\n",
      "Distribución en Train: {0: 439, 1: 273}\n",
      "Distribución en Test:  {0: 110, 1: 69}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. DIVISION DE DATOS (Train 80% / Test 20%)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. DIVISION DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X = df_train.drop('Survived', axis=1)\n",
    "y = df_train['Survived']\n",
    "\n",
    "# Separar X e y\n",
    "# X = df.drop(columns=[\"Survived\"])\n",
    "# y = df[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# División train/test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_prepared, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# print(f\"\\nConjunto de entrenamiento: {X_train.shape}\")\n",
    "# print(f\"Conjunto de validacion: {X_test.shape}\")\n",
    "# print(f\"\\nDistribucion en train: {y_train.value_counts().to_dict()}\")\n",
    "# print(f\"Distribucion en test: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "print(f\"\\nTrain: {X_train.shape} - Test: {X_test.shape}\")\n",
    "print(\"Distribución en Train:\", y_train.value_counts().to_dict())\n",
    "print(\"Distribución en Test: \", y_test.value_counts().to_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "5. ENTRENAMIENTO GRADIENT BOOSTING\n",
      "================================================================================\n",
      "\n",
      "Modelo entrenado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. ENTRENAMIENTO DEL METODO DE ENSAMBLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. ENTRENAMIENTO GRADIENT BOOSTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Hiperparametros definidos\n",
    "# print(\"\\nHiperparametros del modelo:\")\n",
    "# print(\"  - criterion: gini\")\n",
    "# print(\"  - max_depth: 5\")\n",
    "# print(\"  - min_samples_split: 20\")\n",
    "# print(\"  - min_samples_leaf: 10\")\n",
    "# print(\"  - random_state: 42\")\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "# dt_model = DecisionTreeClassifier(\n",
    "#     criterion='gini',\n",
    "#     max_depth=5,\n",
    "#     min_samples_split=20,\n",
    "#     min_samples_leaf=10,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# dt_model = RandomForestClassifier(\n",
    "#     n_estimators=200, \n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=200,       # más árboles mejora rendimiento\n",
    "    learning_rate=0.05,    # learning rate bajo mejora generalización\n",
    "    max_depth=3,           # profundidad típica recomendada\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModelo entrenado exitosamente\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "6. EVALUACION DEL MODELO\n",
      "================================================================================\n",
      "\n",
      "METRICAS EN TRAIN:\n",
      "  Accuracy:  0.9143\n",
      "  Precision: 0.9344\n",
      "  Recall:    0.8352\n",
      "  F1-Score:  0.8820\n",
      "\n",
      "METRICAS EN TEST:\n",
      "  Accuracy:  0.8156\n",
      "  Precision: 0.8214\n",
      "  Recall:    0.6667\n",
      "  F1-Score:  0.7360\n",
      "  ROC-AUC:   0.8136\n",
      "\n",
      "REPORTE DE CLASIFICACION (Validacion):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No sobrevivio       0.81      0.91      0.86       110\n",
      "   Sobrevivio       0.82      0.67      0.74        69\n",
      "\n",
      "     accuracy                           0.82       179\n",
      "    macro avg       0.82      0.79      0.80       179\n",
      " weighted avg       0.82      0.82      0.81       179\n",
      "\n",
      "\n",
      "Gráficos guardados: cm_gradient_boosting.png, roc_gradient_boosting.png\n",
      "\n",
      "Modelo guardado como: modelo_gradient_boosting.joblib\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO EXITOSAMENTE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. EVALUACION DEL MODELO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. EVALUACION DEL MODELO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Predicciones\n",
    "# y_train_pred = dt_model.predict(X_train)\n",
    "# y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "y_train_pred = gb_model.predict(X_train)\n",
    "y_test_pred = gb_model.predict(X_test)\n",
    "y_test_proba = gb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# y_pred = dt_model.predict(X_test)\n",
    "# y_proba = dt_model.predict_proba(X_test)[:,1] if hasattr(dt_model, \"predict_proba\") else None\n",
    "\n",
    "# Metricas en Train\n",
    "print(\"\\nMETRICAS EN TRAIN:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_train, y_train_pred):.4f}\")\n",
    "\n",
    "# Metricas en Test\n",
    "print(\"\\nMETRICAS EN TEST:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "# Reporte de clasificacion\n",
    "print(\"\\nREPORTE DE CLASIFICACION (Validacion):\")\n",
    "print(classification_report(y_test, y_test_pred, \n",
    "                          target_names=['No sobrevivio', 'Sobrevivio']))\n",
    "\n",
    "\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# prec = precision_score(y_test, y_pred)\n",
    "# rec = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 5. MATRIZ DE CONFUSIÓN\n",
    "# ============================================================================\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "# plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matriz de Confusión - Gradient Boosting\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cm_gradient_boosting.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 6. CURVA ROC\n",
    "# ============================================================================\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_test_proba)\n",
    "plt.title(\"Curva ROC - Gradient Boosting\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_gradient_boosting.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nGráficos guardados: cm_gradient_boosting.png, roc_gradient_boosting.png\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 7. GUARDAR MODELO\n",
    "# ============================================================================\n",
    "\n",
    "joblib.dump(gb_model, \"modelo_gradient_boosting.joblib\")\n",
    "print(\"\\nModelo guardado como: modelo_gradient_boosting.joblib\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
